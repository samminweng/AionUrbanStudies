Cluster,NumTopics,KeyPhraseScore,KeyPhrase_Words,KeyPhrases
-1,3,-0.95,"[(['learning', 'neural network', 'deep', 'tree', 'random forest'], -1.618), (['imagery', 'image', 'satellite', 'data', 'remote sensing'], -0.418), (['urban', 'planning', 'classification', 'land', 'cover'], -0.815)]","[{'topic_words': ['learning', 'neural network', 'deep', 'tree', 'random forest'], 'score': -1.618, 'word_docIds': {'learning': [8, 74, 92, 113, 137, 158, 283, 285, 289, 378, 437, 443, 452, 476, 531], 'neural network': [8, 92, 137, 312, 378, 452], 'deep': [8, 92, 113, 137, 289, 378], 'tree': [137, 312, 437, 443, 452], 'random forest': [92, 285, 289, 443, 476]}, 'key-phrases': ['deep learning model', 'deep learning algorithms', 'deep learning', 'tree specie classification', 'tree', 'machine learning algorithms', 'generalized machine learning', 'deciduous tree', 'random forest', 'optical data', 'neural network', 'Geographic Information system', 'GEE publication', 'fractal net evolution', 'digital map', 'convolutional neural network', 'classification road extraction', 'big geo data', 'Accurate road extraction'], 'NumDocs': 14, 'DocIds': [8, 92, 113, 137, 158, 283, 285, 289, 312, 378, 437, 443, 452, 476]}, {'topic_words': ['imagery', 'image', 'satellite', 'data', 'remote sensing'], 'score': -0.418, 'word_docIds': {'imagery': [8, 74, 92, 137, 283, 378, 444, 531], 'image': [8, 74, 92, 113, 137, 158, 283, 285, 289, 312, 378, 437, 443, 444, 452, 476, 531], 'satellite': [8, 74, 92, 158, 283, 531], 'data': [8, 74, 92, 158, 283, 285, 289, 312, 378, 437, 443, 444, 452, 476, 531], 'remote sensing': [74, 92, 113, 158, 283, 285, 289, 437, 443, 452, 531]}, 'key-phrases': ['satellite imagery', 'Landsat satellite imagery', 'single satellite', 'satellite image', 'multiscale rapid detection', 'multiscale Gabor filter', 'aerial imagery', 'vegetation specie mapping', 'UAV datasets', 'Sentinel datasets', 'scene Biome dataset', 'SAR feature', 'robust feature', 'Road centerline extraction', 'remote sensing', 'Multiscale road centerline', 'local contextual cue', 'LiDAR data', 'integrated monitoring', 'Hyperspectral image', 'hyperspectral data', 'disaster risk assessment', 'developed dataset', 'climate analysis', 'change detection', 'centerline extraction method', 'air quality data'], 'NumDocs': 16, 'DocIds': [8, 74, 92, 113, 137, 158, 283, 285, 289, 312, 378, 437, 443, 444, 476, 531]}, {'topic_words': ['urban', 'planning', 'classification', 'land', 'cover'], 'score': -0.815, 'word_docIds': {'urban': [8, 74, 92, 113, 158, 283, 285, 289, 312, 378, 437, 443, 444, 452, 476, 531], 'planning': [8, 74, 92, 113, 158, 283, 285, 289, 312, 378, 443, 452], 'classification': [74, 92, 113, 285, 289, 312, 378, 437, 444, 476, 531], 'land': [74, 92, 283, 285, 289, 312, 443, 452, 476, 531], 'cover': [92, 113, 285, 312, 452, 476, 531]}, 'key-phrases': ['land cover classification', 'urban land cover', 'land cover extraction', 'greenery land cover', 'cover classification', 'multilabel classification', 'Land cover map', 'image classification task', 'image classification', 'high classification accuracy', 'CNN classification', 'cloud classification', 'urban planning', 'urban greenery information', 'unsupervised spectral unmixing', 'unreinforced masonry building', 'unlabeled learning classifier', 'training pixel', 'sustainable urban planning', 'roof diaphragms', 'populated emirate', 'nonroad area removing', 'mislabeled training sample', 'greenery auto extraction', 'common building typology', 'cloud omission error', 'cloud mask', 'cadastral parcel layer'], 'NumDocs': 15, 'DocIds': [74, 92, 113, 137, 158, 283, 285, 289, 312, 437, 443, 444, 452, 476, 531]}]"
0,3,-1.401,"[(['spatial', 'image', 'forest', 'random', 'remote sensing'], -1.467), (['urban', 'land', 'planning', 'use', 'forest'], -0.768), (['machine', 'learning', 'classification', 'classifier', 'logic'], -1.969)]","[{'topic_words': ['spatial', 'image', 'forest', 'random', 'remote sensing'], 'score': -1.467, 'word_docIds': {'spatial': [6, 42, 114, 119, 120, 167, 171, 175, 190, 208, 213, 225, 252, 293, 299, 310, 317, 347, 361, 420, 426, 458, 464, 475, 524, 553, 570, 572, 578, 582, 590, 593, 594], 'image': [11, 42, 72, 114, 120, 167, 171, 175, 213, 230, 252, 302, 303, 317, 320, 331, 347, 361, 374, 391, 458, 464, 475, 497, 515, 551, 565, 569, 570, 572, 576, 578, 588, 590], 'forest': [11, 90, 119, 120, 135, 167, 190, 208, 213, 252, 293, 303, 310, 316, 317, 320, 331, 347, 374, 391, 426, 458, 475, 497, 565, 576, 590], 'random': [11, 90, 119, 167, 190, 208, 213, 252, 303, 310, 316, 317, 320, 331, 347, 391, 420, 458, 475, 497, 565, 572, 576], 'remote sensing': [72, 120, 171, 182, 252, 316, 320, 331, 361, 374, 391, 464, 497, 570, 572, 576, 578, 590]}, 'key-phrases': ['supervised image classification', 'spatial classification', 'OLI image classification', 'image classification approach', 'image classification', 'UAV image', 'spatial transformation rule', 'spatial pattern', 'spatial modeling', 'spatial logistic regression', 'spatial distribution', 'spatial data quality', 'spatial data', 'spatial characteristic', 'spatial attribute', 'spatial', 'Sentinel image', 'satellite imagery', 'satellite image fusion', 'satellite image', 'resolution satellite image', 'Random Forests classification', 'multispectral satellite image', 'multispectral image', 'Landsat imagery archive', 'Landsat imagery', 'Landsat image', 'landcover classification', 'land use classification', 'land cover classification', 'infrastructure classification framework', 'image analysis', 'IKONOS satellite imagery', 'geospatial variable', 'geospatial application', 'classification tree', 'XGBoost algorithm', 'volunteered geographic information', 'Various graph measure', 'use change modeling', 'urban data', 'unmanned aerial vehicle', 'unchanged data', 'time series', 'texture analysis', 'system adaptation planning', 'synthetic aperture radar', 'spatiotemporal uncertainty', 'Spatiotemporal modeling', 'site transformation', 'sensed activity data', 'semantic inpainting algorithm', 'satellite big data', 'rotation forest', 'remote sensing', 'regression tree', 'recognition system', 'Random Forest machine', 'Random Forest algorithm', 'random forest', 'LULC change detection', 'Logistic regression analysis', 'Landsat data stack', 'Landsat data', 'intensity analysis', 'integrated model', 'industrial land recognition', 'GIS modelling', 'GIS functionality', 'GIS approach', 'geographic information', 'feature importance', 'elevation model', 'decision tree', 'composite change detection', 'cluster mean', 'change modeling', 'change detection analysis', 'change detection algorithm', 'cellular automaton model', 'cellular automaton', 'cellular automata', 'boosted regression tree', 'area change detection'], 'NumDocs': 55, 'DocIds': [6, 11, 42, 72, 90, 100, 114, 120, 167, 171, 175, 182, 208, 213, 225, 230, 252, 293, 299, 303, 310, 316, 317, 320, 331, 344, 347, 352, 361, 374, 391, 420, 436, 458, 464, 475, 494, 497, 509, 515, 524, 553, 554, 565, 569, 570, 572, 576, 578, 582, 588, 589, 590, 593, 594]}, {'topic_words': ['urban', 'land', 'planning', 'use', 'forest'], 'score': -0.768, 'word_docIds': {'urban': [6, 11, 42, 72, 90, 100, 114, 119, 135, 167, 171, 175, 182, 190, 208, 213, 225, 230, 252, 256, 288, 293, 299, 302, 303, 310, 316, 317, 320, 331, 347, 348, 352, 361, 374, 391, 420, 426, 436, 458, 464, 475, 494, 497, 509, 515, 524, 551, 553, 565, 569, 570, 572, 576, 578, 582, 588, 589, 590, 593, 594], 'land': [11, 42, 72, 90, 114, 119, 120, 135, 167, 171, 175, 182, 208, 213, 225, 252, 256, 288, 293, 299, 302, 303, 310, 316, 317, 320, 331, 344, 348, 361, 374, 391, 426, 436, 458, 464, 475, 494, 497, 509, 515, 524, 551, 553, 554, 565, 569, 570, 572, 576, 578, 582, 588, 589, 590, 593], 'planning': [11, 42, 72, 90, 100, 114, 119, 120, 135, 167, 171, 175, 182, 190, 208, 213, 230, 252, 256, 288, 293, 299, 302, 303, 310, 317, 320, 331, 347, 352, 361, 374, 391, 420, 426, 436, 458, 464, 494, 497, 509, 515, 551, 569, 570, 576, 582, 590, 593], 'use': [11, 42, 72, 90, 119, 120, 135, 167, 171, 175, 182, 190, 208, 213, 225, 252, 256, 288, 293, 299, 302, 303, 310, 316, 317, 320, 331, 347, 348, 374, 391, 426, 436, 458, 464, 475, 494, 497, 515, 524, 551, 553, 554, 565, 569, 570, 572, 576, 582, 588, 589, 590, 593, 594], 'forest': [11, 90, 119, 120, 135, 167, 190, 208, 213, 252, 293, 303, 310, 316, 317, 320, 331, 347, 374, 391, 426, 458, 475, 497, 565, 576, 590]}, 'key-phrases': ['urban land use', 'urban land prediction', 'urban land market', 'urban land cover', 'land use policy', 'land use master', 'land use mapping', 'land use map', 'land use evolution', 'land use dynamic', 'land use datasets', 'land use data', 'land use class', 'land use change', 'land use', 'future land use', 'accelerated land use', 'use planning', 'urbanization rate', 'urbanization', 'urban water infrastructure', 'urban vegetation mapping', 'urban transition rule', 'urban structure type', 'urban stormwater management', 'urban sprawl', 'urban slum area', 'urban planning sector', 'urban planning model', 'urban planning decision', 'urban planning', 'urban hydrologic modelling', 'urban growth planning', 'urban growth map', 'urban growth', 'urban forest cover', 'urban feature extraction', 'urban expansion trend', 'urban environment', 'urban development', 'urban area', 'sustainable urbanization', 'surface urban heat', 'smart urban planning', 'shrubland coverage', 'sensed land cover', 'residential land growth', 'residential land', 'Rapid urban growth', 'predicted urban expansion', 'populated urban region', 'planned urban zone', 'OSM urban area', 'natural land', 'landscape diversity', 'landcover map', 'land price prediction', 'land owner', 'land expansion', 'land cover mapping', 'land cover map', 'land cover class', 'land cover change', 'land cover', 'land consumption', 'land change science', 'land change model', 'land boundary data', 'inefficient industrial land', 'hierarchical farmland', 'future urban extent', 'future land management', 'future land change', 'croplands', 'complex urban area', 'binary urban footprint', 'annual urbanization', 'water demand modeling', 'water consumption data', 'Taliban regime', 'stream water quality', 'storm water management', 'spatial trend', 'socioeconomic inequality', 'smart city growth', 'small polish city', 'slum mapping', 'settlement pattern', 'sand consumption', 'road system', 'residential low impact', 'regional planning relies', 'population forecasting', 'pollutant concentration data', 'planning coastal area', 'perennial drainage', 'multivariate municipality data', 'material consumption analysis', 'Lahore city', 'Interregional comparison', 'intermediate city', 'hydrologic risk', 'housing dispersal', 'growth simulation', 'growth modeling', 'grey development', 'green space analysis', 'green roofs', 'green infrastructure', 'forest', 'facing sustainability threat', 'environmental change', 'ecosystem service', 'Earth Observation datasets', 'Earth Engine platform', 'difference vegetation index', 'development zone construction', 'cover change analysis', 'conflict zone', 'combinatory trend', 'city worldwide', 'census tract', 'catchment area', 'building height', 'Athens area', 'annual air pollution'], 'NumDocs': 64, 'DocIds': [6, 11, 42, 72, 90, 100, 114, 119, 120, 135, 167, 171, 175, 182, 190, 208, 213, 225, 230, 252, 256, 288, 293, 299, 302, 303, 310, 316, 317, 320, 331, 344, 347, 348, 352, 361, 374, 391, 420, 426, 436, 458, 464, 475, 494, 497, 509, 515, 524, 551, 553, 554, 565, 569, 570, 572, 576, 578, 582, 588, 589, 590, 593, 594]}, {'topic_words': ['machine', 'learning', 'classification', 'classifier', 'logic'], 'score': -1.969, 'word_docIds': {'machine': [11, 42, 72, 90, 100, 114, 119, 120, 167, 171, 175, 182, 190, 208, 230, 252, 288, 299, 302, 303, 310, 317, 320, 331, 347, 348, 352, 361, 374, 391, 420, 426, 436, 458, 464, 475, 494, 497, 515, 524, 551, 553, 554, 565, 569, 570, 572, 576, 578, 582, 588, 589, 590, 594], 'learning': [11, 42, 72, 90, 100, 114, 119, 120, 171, 175, 182, 190, 208, 230, 252, 256, 288, 299, 302, 303, 310, 317, 320, 331, 347, 348, 352, 361, 374, 391, 420, 426, 436, 458, 464, 475, 494, 497, 509, 515, 524, 551, 553, 554, 565, 569, 570, 572, 576, 582, 588, 589, 590, 594], 'classification': [11, 42, 72, 167, 171, 208, 252, 293, 302, 303, 316, 320, 331, 344, 361, 374, 391, 458, 464, 475, 497, 515, 524, 551, 554, 565, 569, 576, 578, 588, 589, 590, 594], 'classifier': [11, 167, 213, 252, 299, 302, 316, 317, 320, 361, 391, 475, 497, 565, 572, 576, 578, 590], 'logic': [120, 135, 230, 288, 299, 352, 361, 426, 475, 551, 554, 576, 578, 582]}, 'key-phrases': ['machine learning technique', 'machine learning algorithms', 'machine learning', 'extreme learning machine', 'support vector machine', 'learning model', 'inductive learning algorithms', 'high classification', 'deep learning method', 'deep learning', 'classification strategy', 'classification rule', 'classification model', 'classification method', 'classification map', 'classification algorithms', 'classification', 'weighted regression', 'transition rule mining', 'transition map', 'training dataset', 'test dataset', 'Systematic data mining', 'SVM technique', 'SVM modeling', 'support vector regression', 'semantic net', 'RMSE value', 'RF classifier', 'regression domain', 'prediction error', 'overestimation', 'novel method', 'neural network method', 'model prediction', 'ML concept', 'logic', 'information entropy', 'ge classifier', 'fuzzy inference system', 'extracted knowledge', 'explorative model', 'ensemble classifier', 'endogenous optimization method', 'data weighting', 'data mining tool', 'complex map production', 'classifier', 'big data', 'basis function network', 'automatic mapping', 'artificial neural network', 'adversarial network', 'advanced mathematical algorithms', 'adoption strategy', 'accurate prediction'], 'NumDocs': 45, 'DocIds': [6, 72, 90, 100, 114, 119, 167, 175, 190, 208, 225, 252, 256, 288, 293, 299, 302, 303, 310, 320, 331, 344, 352, 374, 391, 420, 436, 464, 475, 494, 509, 515, 524, 551, 553, 554, 569, 572, 576, 578, 582, 588, 589, 593, 594]}]"
1,3,-1.243,"[(['object', 'small', 'appearance', 'different', 'street'], -2.431), (['urban', 'remote', 'sensing', 'detection', 'planning'], -0.645), (['deep', 'learning', 'network', 'neural', 'convolutional'], -0.652)]","[{'topic_words': ['object', 'small', 'appearance', 'different', 'street'], 'score': -2.431, 'word_docIds': {'object': [16, 46, 128, 141, 165, 226, 234, 237, 259, 314, 460, 469, 473, 525, 547], 'small': [128, 141, 254, 259], 'appearance': [128, 237, 525], 'different': [16, 46, 66, 73, 87, 118, 161, 169, 188, 226, 231, 314, 398, 463, 525], 'street': [73, 183, 314]}, 'key-phrases': ['small object', 'appearance object', 'object', 'different street object'], 'NumDocs': 4, 'DocIds': [128, 259, 314, 460]}, {'topic_words': ['urban', 'remote', 'sensing', 'detection', 'planning'], 'score': -0.645, 'word_docIds': {'urban': [9, 16, 23, 37, 66, 73, 87, 93, 118, 128, 141, 161, 165, 169, 183, 188, 226, 231, 234, 237, 254, 259, 314, 330, 389, 398, 418, 460, 462, 463, 469, 473, 490, 525, 547, 548], 'remote': [16, 23, 37, 46, 66, 73, 87, 118, 161, 169, 188, 226, 231, 237, 254, 259, 330, 398, 460, 469, 473, 490, 525, 547, 548], 'sensing': [16, 23, 37, 46, 66, 73, 87, 118, 161, 169, 188, 226, 231, 237, 254, 259, 330, 398, 469, 473, 490, 525, 547, 548], 'detection': [23, 37, 46, 66, 73, 93, 118, 128, 165, 226, 237, 259, 314, 330, 418, 460, 463, 469, 473, 525, 547], 'planning': [16, 23, 37, 66, 73, 87, 118, 128, 141, 161, 169, 183, 188, 226, 231, 234, 237, 259, 330, 389, 398, 463, 490, 525, 547, 548]}, 'key-phrases': ['fast building detection', 'building detection', 'building change detection', 'automatic building detection', 'aerial building dataset', 'vehicle detection', 'urban change detection', 'shadow detection', 'sensed urban data', 'road network detection', 'road edge detection', 'resolution multispectral data', 'Precise object detection', 'object detection method', 'new data fusion', 'natural feature detection', 'natural disaster detection', 'multispectral data', 'LiDAR data fusion', 'LiDAR data', 'large training dataset', 'large annotated dataset', 'LandUse data set', 'land classification dataset', 'labeled data', 'digital urban data', 'DEM data', 'datasets', 'damage detection', 'change detection', 'building size prediction', 'building footprint', 'building extraction method', 'building extraction accuracy', 'Automatic building extraction', 'area geospatial data', 'aerial image dataset', 'wave signature', 'urbanization lead', 'urban planning', 'urban neighborhood', 'urban intelligent navigator', 'Urban Atlas land', 'urban area', 'unmanned aerial vehicle', 'unlabeled overhead imagery', 'UAV photogrammetry', 'truth land use', 'traditional interpolation method', 'terrain character', 'temporal information', 'subsampled orthophoto', 'spatial feature', 'Spark RDD image', 'single vehicle extraction', 'significant accuracy', 'secondary task', 'satellite imagery', 'SAR mapping', 'resolution aerial imagery', 'remote sensing imagery', 'remote sensing image', 'remote sensing', 'receptive field', 'powerful sensor', 'new GeoAI research', 'natural image field', 'natural disaster evaluation', 'multitemporal satellite image', 'multiscale prediction', 'multiscale feature', 'many visual descriptor', 'large earthquake', 'land cover', 'inpainting', 'impervious surface', 'image SR method', 'hyperspectral system', 'hyperspectral image classification', 'Historical Cityscape', 'high spatial resolution', 'high resolution earth', 'feature fusion', 'elevation', 'earth observation', 'earth', 'drone', 'discriminative feature', 'difference vegetation index', 'difference feature', 'descriptor extraction', 'contour extraction', 'computer vision', 'complex urban study', 'Coastal development', 'climate zone mapping', 'change map', 'bathymetry estimation', 'attention', 'aerial orthophotos', 'aerial image', 'accuracy', 'abundant spectral signature'], 'NumDocs': 37, 'DocIds': [9, 16, 23, 37, 46, 66, 73, 87, 93, 118, 128, 141, 161, 165, 169, 183, 188, 226, 231, 234, 237, 254, 259, 314, 330, 389, 398, 418, 460, 462, 463, 469, 473, 490, 525, 547, 548]}, {'topic_words': ['deep', 'learning', 'network', 'neural', 'convolutional'], 'score': -0.652, 'word_docIds': {'deep': [16, 23, 37, 46, 66, 73, 87, 93, 128, 141, 161, 165, 169, 188, 226, 237, 254, 259, 330, 398, 418, 462, 469, 473, 490, 547, 548], 'learning': [9, 16, 23, 37, 46, 66, 73, 87, 93, 118, 128, 141, 165, 169, 188, 226, 231, 234, 237, 254, 259, 314, 330, 389, 398, 418, 460, 462, 469, 473, 490, 525, 547, 548], 'network': [9, 16, 23, 37, 46, 66, 73, 87, 93, 118, 161, 188, 234, 237, 254, 314, 389, 398, 418, 460, 462, 469, 473, 490, 547, 548], 'neural': [9, 46, 66, 73, 87, 93, 118, 161, 234, 237, 254, 314, 398, 418, 460, 469, 473, 490, 547, 548], 'convolutional': [46, 66, 87, 118, 161, 188, 234, 237, 254, 314, 398, 418, 460, 462, 469, 473, 490, 547, 548]}, 'key-phrases': ['supervised deep learning', 'new deep learning', 'deep learning scheme', 'deep learning model', 'deep learning framework', 'deep learning algorithm', 'deep learning', 'unsupervised feature learning', 'transfer learning', 'segmentation network', 'residual network', 'neural network', 'extreme learning machine', 'deep supervision module', 'deep supervision', 'deep representation', 'deep method', 'deep machine', 'Deep learning paradigm', 'deep architecture', 'convolutional neural network', 'convolutional network', 'cloud siamese network', 'video semantic segmentation', 'unsupervised scene classification', 'spatial pyramid pooling', 'sparse coding', 'semantic segmentation task', 'semantic segmentation', 'semantic representation', 'scene image classifier', 'scene classification task', 'Random Forest algorithm', 'pair segmentation', 'learned uncertainty estimate', 'invariant augmentation', 'generative adversarial net', 'encoder', 'efficient classification', 'conditional adversarial term', 'CNNs parameter', 'CNN architecture', 'cloud coverage', 'classifier', 'binary feature classification', 'binary decomposition', 'adversarial training'], 'NumDocs': 36, 'DocIds': [9, 16, 23, 37, 46, 66, 73, 87, 93, 118, 128, 141, 161, 165, 169, 183, 188, 226, 231, 234, 237, 254, 259, 314, 330, 389, 398, 418, 462, 463, 469, 473, 490, 525, 547, 548]}]"
2,4,-1.329,"[(['feature', 'classification', 'contextual', 'spatiotemporal', 'neighborhood'], -2.274), (['learning', 'machine', 'network', 'deep', 'random forest'], -1.29), (['image', 'classification', 'satellite', 'SAR', 'remote sensing'], -1.318), (['urban', 'map', 'land', 'mapping', 'planning'], -0.433)]","[{'topic_words': ['feature', 'classification', 'contextual', 'spatiotemporal', 'neighborhood'], 'score': -2.274, 'word_docIds': {'feature': [59, 78, 144, 245, 251, 260, 393, 427, 479, 559], 'classification': [78, 96, 144, 193, 282, 393, 427, 479, 559], 'contextual': [59, 193, 559], 'spatiotemporal': [245, 328], 'neighborhood': [59, 245, 368]}, 'key-phrases': ['contextual feature', 'spatiotemporal neighborhood feature', 'nonlinear feature space', 'LULC classification', 'location contextual information', 'learning LU classification', 'LCLU classification', 'hierarchic feature representation'], 'NumDocs': 8, 'DocIds': [59, 96, 144, 193, 245, 393, 427, 479]}, {'topic_words': ['learning', 'machine', 'network', 'deep', 'random forest'], 'score': -1.29, 'word_docIds': {'learning': [78, 96, 144, 186, 193, 212, 245, 251, 260, 282, 328, 368, 393, 427, 479, 559], 'machine': [78, 96, 144, 186, 212, 245, 251, 260, 282, 328, 368, 393, 427, 479, 559], 'network': [78, 186, 193, 245, 328, 427, 479, 559], 'deep': [96, 144, 193, 479, 559], 'random forest': [78, 186, 212, 245, 251, 260, 393, 479]}, 'key-phrases': ['deep learning network', 'deep learning configuration', 'deep learning', 'deep belief network', 'transfer learning', 'neural network paradigm', 'machine learning algorithm', 'machine learning', 'highway unit network', 'ensemble learning', 'artificial neural network', 'zonal modeling strategy', 'random forest', 'large datasets', 'fish swarm algorithm', 'expansion cell', 'cellular automaton model', 'cellular automata', 'big data'], 'NumDocs': 16, 'DocIds': [78, 96, 130, 144, 186, 193, 212, 245, 251, 260, 328, 368, 393, 427, 479, 559]}, {'topic_words': ['image', 'classification', 'satellite', 'SAR', 'remote sensing'], 'score': -1.318, 'word_docIds': {'image': [59, 78, 96, 144, 186, 193, 251, 282, 368, 393, 427, 479], 'classification': [78, 96, 144, 193, 282, 393, 427, 479, 559], 'satellite': [59, 96, 368], 'SAR': [393, 479, 559], 'remote sensing': [78, 96, 144, 212, 251, 282, 393, 427, 479, 559]}, 'key-phrases': ['satellite imagery', 'SAR image classification', 'RS image classification', 'image classification method', 'hyperspectral image classification', 'UAV image', 'street view image', 'satellite data', 'SAR image', 'image segmentation optimization', 'spectral information', 'segmentation approach', 'sar data', 'remote sensing', 'precision agriculture', 'PEN Net classifier', 'nighttime light'], 'NumDocs': 11, 'DocIds': [59, 96, 144, 186, 193, 260, 282, 393, 427, 479, 559]}, {'topic_words': ['urban', 'map', 'land', 'mapping', 'planning'], 'score': -0.433, 'word_docIds': {'urban': [59, 78, 96, 130, 144, 186, 193, 212, 245, 251, 260, 282, 328, 368, 427, 479, 559], 'map': [59, 78, 96, 186, 193, 212, 245, 251, 260, 328, 368, 393, 559], 'land': [59, 78, 96, 130, 144, 193, 212, 245, 260, 282, 328, 393, 479, 559], 'mapping': [78, 96, 186, 193, 212, 251, 260, 368, 393, 559], 'planning': [59, 78, 96, 144, 186, 193, 212, 245, 251, 260, 282, 393, 427, 479, 559]}, 'key-phrases': ['urban land use', 'sustainable urban land', 'optimal urban land', 'Urban population distribution', 'urban planning', 'urban growth simulation', 'population mapping', 'population density', 'new urban growth', 'land use classification', 'land use category', 'land parcel', 'land cover classification', 'land cover', 'effective urban policy', 'dynamic land use', 'census population', 'USI map', 'Urbanization process', 'suitability index', 'spatial pattern', 'spatial heterogeneity', 'smart city', 'slum area', 'Regional mapping', 'Population spatialization', 'monetary poverty', 'mapping', 'map', 'geographic information system', 'flood loss assessment', 'distribution map', 'cover classification', 'census data'], 'NumDocs': 16, 'DocIds': [59, 78, 96, 130, 186, 193, 212, 245, 251, 260, 282, 328, 368, 393, 479, 559]}]"
3,3,-0.549,"[(['point', 'cloud', 'lidar', 'airborne', 'urban'], -0.114), (['urban', 'detection', 'extraction', 'planning', 'light'], -0.972), (['classification', 'machine', 'image', 'support', 'vector'], -0.562)]","[{'topic_words': ['point', 'cloud', 'lidar', 'airborne', 'urban'], 'score': -0.114, 'word_docIds': {'point': [89, 129, 236, 327, 478, 528, 592], 'cloud': [89, 129, 236, 327, 478, 528, 592], 'lidar': [89, 129, 162, 236, 327, 528, 557, 563], 'airborne': [89, 129, 236, 528, 563], 'urban': [89, 106, 129, 153, 162, 236, 301, 327, 333, 405, 478, 496, 507, 528, 552, 557, 563, 592]}, 'key-phrases': ['urban point cloud', 'point cloud labelling', 'point cloud classification', 'LiDAR point cloud', 'classify LiDAR point', 'airborne lidar', 'Riegl Terrestrial laser', 'LiDAR imagery', 'airborne LIDAR data'], 'NumDocs': 9, 'DocIds': [89, 129, 236, 327, 478, 528, 557, 563, 592]}, {'topic_words': ['urban', 'detection', 'extraction', 'planning', 'light'], 'score': -0.972, 'word_docIds': {'urban': [89, 106, 129, 153, 162, 236, 301, 327, 333, 405, 478, 496, 507, 528, 552, 557, 563, 592], 'detection': [89, 106, 129, 153, 236, 301, 333, 507, 528, 557, 563], 'extraction': [89, 106, 153, 333, 405, 478, 496, 507, 552, 557, 592], 'planning': [89, 106, 129, 153, 236, 301, 327, 333, 405, 478, 496, 507, 552, 557, 563], 'light': [89, 129, 162, 236, 528, 557, 563]}, 'key-phrases': ['urban area extraction', 'building extraction', 'urban water type', 'urban tree classification', 'urban planning', 'urban development', 'urban city modelling', 'road infrastructure extraction', 'large urban scene', 'individual building', 'green urban area', 'detected building', 'complex urban area', 'accurate urban mapping', 'water body', 'touristic development', 'surface openness', 'roofs', 'roof superstructure classification', 'Road detection', 'light detection', 'edge detection'], 'NumDocs': 16, 'DocIds': [89, 106, 129, 153, 162, 236, 301, 327, 333, 405, 496, 507, 528, 552, 557, 563]}, {'topic_words': ['classification', 'machine', 'image', 'support', 'vector'], 'score': -0.562, 'word_docIds': {'classification': [89, 129, 153, 162, 327, 333, 405, 478, 507, 528, 552, 557, 563, 592], 'machine': [89, 106, 129, 153, 162, 236, 301, 327, 333, 405, 478, 496, 507, 528, 552, 557], 'image': [106, 129, 153, 162, 236, 301, 333, 405, 496, 507, 552, 557], 'support': [89, 106, 129, 153, 162, 333, 405, 496, 507, 557, 563, 592], 'vector': [89, 106, 129, 153, 162, 405, 496, 507, 528, 557]}, 'key-phrases': ['satellite imagery', 'satellite image segmentation', 'satellite image need', 'satellite image', 'resolution satellite image', 'Pl√©iades satellite image', 'specie classification', 'object classification result', 'infrared imagery', 'image interpretation', 'Copernicus mission satellite', 'classification accuracy', 'classification', 'vegetation', 'support vector machine', 'supervoxels', 'supervised machine', 'shape descriptor', 'semantic labelling', 'scene object', 'robust segmentation', 'robust feature extraction', 'random forest', 'Planet database', 'pixel level', 'natural disaster prediction', 'multiple feature space', 'meaningful semantic class', 'Jaccard index', 'imbalanced data', 'hyperspectral reflectance', 'Forest classifier', 'feature extraction', 'Ensemble method', 'disaster risk management', 'deep learning', 'data fusion', 'convolution neural network', 'connected component analysis', 'Conditional random field', 'classifier', 'binary class', 'backpropagation neural network', 'automatic identification', 'adaptive data reduction'], 'NumDocs': 18, 'DocIds': [89, 106, 129, 153, 162, 236, 301, 327, 333, 405, 478, 496, 507, 528, 552, 557, 563, 592]}]"
